{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14eadfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.2 regex-2024.5.15 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.41.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926dc8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (2.1.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.23.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-0.30.1\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd663a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.41.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: accelerate in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb02a43d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --quiet bitsandbytes\n",
    "!pip install --quiet --upgrade transformers\n",
    "!pip install --quiet --upgrade accelerate\n",
    "!pip install --quiet sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77379354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (21.3)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (4.66.2)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->optuna) (3.1.2)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 greenlet-3.0.3 optuna-3.6.1 sqlalchemy-2.0.30\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275ca5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c01260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed02583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3e11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9828562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abea9d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Context</th>\n",
       "      <th>Team_1</th>\n",
       "      <th>Team_2</th>\n",
       "      <th>Winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1426261.json</td>\n",
       "      <td>Cricket match played on city Mohali on 2024-04...</td>\n",
       "      <td>Sunrisers Hyderabad (SH)</td>\n",
       "      <td>Punjab Kings (PK)</td>\n",
       "      <td>Sunrisers Hyderabad (SH)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1359507.json</td>\n",
       "      <td>Cricket match played on city Kolkata on 2023-0...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Kolkata Knight Riders (KKR)</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392217.json</td>\n",
       "      <td>Cricket match played on city Kimberley on 2009...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Rajasthan Royals (RR)</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1254112.json</td>\n",
       "      <td>Cricket match played on city Sharjah on 2021-1...</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "      <td>Delhi Capitals (DC)</td>\n",
       "      <td>Delhi Capitals (DC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>829817.json</td>\n",
       "      <td>Cricket match played on city Mumbai on 2015-05...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename                                            Context  \\\n",
       "0  1426261.json  Cricket match played on city Mohali on 2024-04...   \n",
       "1  1359507.json  Cricket match played on city Kolkata on 2023-0...   \n",
       "2   392217.json  Cricket match played on city Kimberley on 2009...   \n",
       "3  1254112.json  Cricket match played on city Sharjah on 2021-1...   \n",
       "4   829817.json  Cricket match played on city Mumbai on 2015-05...   \n",
       "\n",
       "                      Team_1                       Team_2  \\\n",
       "0   Sunrisers Hyderabad (SH)            Punjab Kings (PK)   \n",
       "1  Chennai Super Kings (CSK)  Kolkata Knight Riders (KKR)   \n",
       "2  Chennai Super Kings (CSK)        Rajasthan Royals (RR)   \n",
       "3        Mumbai Indians (MI)          Delhi Capitals (DC)   \n",
       "4  Chennai Super Kings (CSK)          Mumbai Indians (MI)   \n",
       "\n",
       "                      Winner  \n",
       "0   Sunrisers Hyderabad (SH)  \n",
       "1  Chennai Super Kings (CSK)  \n",
       "2  Chennai Super Kings (CSK)  \n",
       "3        Delhi Capitals (DC)  \n",
       "4        Mumbai Indians (MI)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('context_text_data_updated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ea3eb93-8dca-4e60-a684-9140007d19e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cricket match played on city Mumbai on 2015-05-19 in the stadium Wankhede Stadium between Chennai Super Kings (CSK) and Mumbai Indians (MI), toss is won by Mumbai Indians and they have decided to bat. Players for Chennai Super Kings (CSK) are DR Smith, MEK Hussey, F du Plessis, SK Raina, MS Dhoni, DJ Bravo, RA Jadeja, P Negi, R Ashwin, MM Sharma, A Nehra and players for Mumbai Indians (MI) are LMP Simmons, PA Patel, RG Sharma, KA Pollard, HH Pandya, AT Rayudu, Harbhajan Singh, J Suchith, MJ McClenaghan, R Vinay Kumar, SL Malinga.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Context'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac2a99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mumbai Indians (MI)                  142\n",
       "Chennai Super Kings (CSK)            138\n",
       "Kolkata Knight Riders (KKR)          129\n",
       "Royal Challengers Bangalore (RCB)    114\n",
       "Rajasthan Royals (RR)                110\n",
       "Sunrisers Hyderabad (SH)              86\n",
       "Kings XI Punjab (KXP)                 85\n",
       "Delhi Daredevils (DD)                 67\n",
       "Delhi Capitals (DC)                   45\n",
       "Deccan Chargers (DC)                  29\n",
       "Gujarat Titans (GT)                   28\n",
       "Punjab Kings (PK)                     24\n",
       "Lucknow Super Giants (LSG)            24\n",
       "None (N)                              19\n",
       "Gujarat Lions (GL)                    13\n",
       "Pune Warriors (PW)                    12\n",
       "Rising Pune Supergiant (RPS)          10\n",
       "Royal Challengers Bengaluru (RCB)      7\n",
       "Kochi Tuskers Kerala (KTK)             6\n",
       "Rising Pune Supergiants (RPS)          5\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "304ad76d-4d7a-4810-8457-2bc4931aa48a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "team_mapping = {\n",
    "    'Royal Challengers Bengaluru (RCB)': 'Royal Challengers Bangalore (RCB)',\n",
    "    'Rising Pune Supergiants (RPS)': 'Rising Pune Supergiant (RPS)',\n",
    "    'Punjab Kings (PK)': 'Kings XI Punjab (KXIP)',\n",
    "    'Kings XI Punjab (KXP)': 'Kings XI Punjab (KXIP)',\n",
    "    'Delhi Daredevils (DD)': 'Delhi Capitals (DC)',\n",
    "    'Sunrisers Hyderabad (SH)': 'Sunrisers Hyderabad (SRH)',\n",
    "    'Deccan Chargers (DC)': 'Sunrisers Hyderabad (SRH)',\n",
    "    'Pune Warriors (PW)': 'Rising Pune Supergiant (RPS)',\n",
    "    'Gujarat Lions (GL)': 'Gujarat Titans (GT)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a115d3-6387-45b2-b87f-18d6018026ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Winner'] = df['Winner'].replace(team_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7bfde52-ddcd-49f8-9102-72401a70441e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['Winner'] != 'None (N)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa02335-f785-4707-9cc6-e8ff4ed2326a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['Winner'] != 'Kochi Tuskers Kerala (KTK)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87c7c597-9314-427d-a4c9-9abb0636b731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[df['Winner'] != 'Rising Pune Supergiant (RPS)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01cbb538-7c2b-4c02-a06e-f41ed624a664",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mumbai Indians (MI)                  142\n",
       "Chennai Super Kings (CSK)            138\n",
       "Kolkata Knight Riders (KKR)          129\n",
       "Royal Challengers Bangalore (RCB)    121\n",
       "Sunrisers Hyderabad (SRH)            115\n",
       "Delhi Capitals (DC)                  112\n",
       "Rajasthan Royals (RR)                110\n",
       "Kings XI Punjab (KXIP)               109\n",
       "Gujarat Titans (GT)                   41\n",
       "Lucknow Super Giants (LSG)            24\n",
       "Name: Winner, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ea905d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sunrisers Hyderabad (SRH)': 0,\n",
       " 'Chennai Super Kings (CSK)': 1,\n",
       " 'Delhi Capitals (DC)': 2,\n",
       " 'Mumbai Indians (MI)': 3,\n",
       " 'Kings XI Punjab (KXIP)': 4,\n",
       " 'Royal Challengers Bangalore (RCB)': 5,\n",
       " 'Gujarat Titans (GT)': 6,\n",
       " 'Kolkata Knight Riders (KKR)': 7,\n",
       " 'Rajasthan Royals (RR)': 8,\n",
       " 'Lucknow Super Giants (LSG)': 9}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_teams = df['Winner'].unique()\n",
    "label_mapping = {team: idx for idx, team in enumerate(unique_teams)}\n",
    "df['Winner_Label'] = df['Winner'].map(label_mapping)\n",
    "label_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "335ff54a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    142\n",
       "1    138\n",
       "7    129\n",
       "5    121\n",
       "0    115\n",
       "2    112\n",
       "8    110\n",
       "4    109\n",
       "6     41\n",
       "9     24\n",
       "Name: Winner_Label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Winner_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe97482b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Context</th>\n",
       "      <th>Team_1</th>\n",
       "      <th>Team_2</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Winner_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1426261.json</td>\n",
       "      <td>Cricket match played on city Mohali on 2024-04...</td>\n",
       "      <td>Sunrisers Hyderabad (SH)</td>\n",
       "      <td>Punjab Kings (PK)</td>\n",
       "      <td>Sunrisers Hyderabad (SRH)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1359507.json</td>\n",
       "      <td>Cricket match played on city Kolkata on 2023-0...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Kolkata Knight Riders (KKR)</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>392217.json</td>\n",
       "      <td>Cricket match played on city Kimberley on 2009...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Rajasthan Royals (RR)</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1254112.json</td>\n",
       "      <td>Cricket match played on city Sharjah on 2021-1...</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "      <td>Delhi Capitals (DC)</td>\n",
       "      <td>Delhi Capitals (DC)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>829817.json</td>\n",
       "      <td>Cricket match played on city Mumbai on 2015-05...</td>\n",
       "      <td>Chennai Super Kings (CSK)</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "      <td>Mumbai Indians (MI)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Filename                                            Context  \\\n",
       "0  1426261.json  Cricket match played on city Mohali on 2024-04...   \n",
       "1  1359507.json  Cricket match played on city Kolkata on 2023-0...   \n",
       "2   392217.json  Cricket match played on city Kimberley on 2009...   \n",
       "3  1254112.json  Cricket match played on city Sharjah on 2021-1...   \n",
       "4   829817.json  Cricket match played on city Mumbai on 2015-05...   \n",
       "\n",
       "                      Team_1                       Team_2  \\\n",
       "0   Sunrisers Hyderabad (SH)            Punjab Kings (PK)   \n",
       "1  Chennai Super Kings (CSK)  Kolkata Knight Riders (KKR)   \n",
       "2  Chennai Super Kings (CSK)        Rajasthan Royals (RR)   \n",
       "3        Mumbai Indians (MI)          Delhi Capitals (DC)   \n",
       "4  Chennai Super Kings (CSK)          Mumbai Indians (MI)   \n",
       "\n",
       "                      Winner  Winner_Label  \n",
       "0  Sunrisers Hyderabad (SRH)             0  \n",
       "1  Chennai Super Kings (CSK)             1  \n",
       "2  Chennai Super Kings (CSK)             1  \n",
       "3        Delhi Capitals (DC)             2  \n",
       "4        Mumbai Indians (MI)             3  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ba46cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    142\n",
       "1    138\n",
       "7    129\n",
       "5    121\n",
       "0    115\n",
       "2    112\n",
       "8    110\n",
       "4    109\n",
       "6     41\n",
       "9     24\n",
       "Name: Winner_Label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Winner_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c92b3a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1041, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67445b58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96c97bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context</th>\n",
       "      <th>Winner_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cricket match played on city Mohali on 2024-04...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cricket match played on city Kolkata on 2023-0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricket match played on city Kimberley on 2009...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cricket match played on city Sharjah on 2021-1...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cricket match played on city Mumbai on 2015-05...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Context  Winner_Label\n",
       "0  Cricket match played on city Mohali on 2024-04...             0\n",
       "1  Cricket match played on city Kolkata on 2023-0...             1\n",
       "2  Cricket match played on city Kimberley on 2009...             1\n",
       "3  Cricket match played on city Sharjah on 2021-1...             2\n",
       "4  Cricket match played on city Mumbai on 2015-05...             3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['Context','Winner_Label']]\n",
    "data = data[0:1000]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3595702b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89a9842d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03bb214bcdf4a5485ac575d842a65dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0525d35c3dd48c7b067fb689742b5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2c6115853b497696369db94176bd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8ced376a434dc1a7ea1545685a23a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41ce977372a64f0abe63a6d94f0261b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "desired_vocab_size = 30522\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', vocab_size=desired_vocab_size)\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26cec340",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2721566",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b75656f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dc24e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = list(data[\"Context\"])\n",
    "y = list(data[\"Winner_Label\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24cb87bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokenized.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "504ad093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train_tokenized['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a15187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4b20f12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "69800d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b92cd570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3cc9b122",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4cb383f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='macro')\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "19be2268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# args = TrainingArguments(\n",
    "#     output_dir=\"output\",\n",
    "#     num_train_epochs=1,\n",
    "#     per_device_train_batch_size=8\n",
    "\n",
    "# )\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96008872-b806-4ddc-9e9b-74adca90d32c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "temp_output_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9616c8d8-2a52-471f-a89a-1394c432b55d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=temp_output_dir,\n",
    "    num_train_epochs=3,  # Try increasing epochs for better results\n",
    "    per_device_train_batch_size=16,  # Increase if GPU memory allows\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    learning_rate=5e-5,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",  # Evaluate during training\n",
    "    save_steps=500,\n",
    "    save_total_limit=3,\n",
    "    fp16=True  # Use mixed precision training\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e70b3d18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:29, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.397900</td>\n",
       "      <td>2.359399</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.010153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.313700</td>\n",
       "      <td>2.320601</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.293600</td>\n",
       "      <td>2.262480</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.025977</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.041152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=36, training_loss=2.3244056701660156, metrics={'train_runtime': 42.1369, 'train_samples_per_second': 56.957, 'train_steps_per_second': 0.854, 'total_flos': 248657806817280.0, 'train_loss': 2.3244056701660156, 'epoch': 2.88})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "06a1a172",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.2420654296875,\n",
       " 'eval_accuracy': 0.13,\n",
       " 'eval_precision': 0.025547691270643748,\n",
       " 'eval_recall': 0.11635610766045548,\n",
       " 'eval_f1': 0.04146198830409357,\n",
       " 'eval_runtime': 0.7305,\n",
       " 'eval_samples_per_second': 273.795,\n",
       " 'eval_steps_per_second': 17.797,\n",
       " 'epoch': 2.88}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0be177c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('First_Mulit_Class_Win_Predictor/tokenizer_config.json',\n",
       " 'First_Mulit_Class_Win_Predictor/special_tokens_map.json',\n",
       " 'First_Mulit_Class_Win_Predictor/vocab.txt',\n",
       " 'First_Mulit_Class_Win_Predictor/added_tokens.json')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = \"First_Mulit_Class_Win_Predictor\"\n",
    "trainer.save_model(new_model)\n",
    "tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563f95ae-f83d-44fe-b586-ed23cc394230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c79a9a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = BertForSequenceClassification.from_pretrained(new_model)\n",
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "99bda056",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07806079, 0.09289068, 0.13897607, 0.06293776, 0.11114101,\n",
       "        0.11057921, 0.12105013, 0.06313595, 0.0897246 , 0.1315038 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"who is going to win if match is played beteen RCB and SRH\"\n",
    "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to(device)\n",
    "outputs = model_2(**inputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408e71c",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2d5c099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
    "    num_train_epochs = trial.suggest_int('num_train_epochs', 2, 5)\n",
    "    per_device_train_batch_size = trial.suggest_categorical('per_device_train_batch_size', [8, 16, 32])\n",
    "    warmup_steps = trial.suggest_int('warmup_steps', 0, 500)\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
    "    logging_steps = trial.suggest_int('logging_steps', 10, 50)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=temp_output_dir,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=per_device_train_batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        learning_rate=learning_rate,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=logging_steps,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        fp16=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    return eval_results['eval_loss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fb6ed1d-b782-41ba-aeaf-8c72a627a7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:49:16,705] A new study created in memory with name: no-name-6bfa59fd-8940-4545-aa6e-9b8da7e95a27\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.204800</td>\n",
       "      <td>2.127769</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.110370</td>\n",
       "      <td>0.163783</td>\n",
       "      <td>0.116633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.942600</td>\n",
       "      <td>1.731660</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.348170</td>\n",
       "      <td>0.377729</td>\n",
       "      <td>0.348596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "[I 2024-05-28 08:50:04,128] Trial 0 finished with value: 1.3454028367996216 and parameters: {'learning_rate': 3.326454578804934e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'warmup_steps': 176, 'weight_decay': 0.03492103067358597, 'logging_steps': 48}. Best is trial 0 with value: 1.3454028367996216.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.310900</td>\n",
       "      <td>1.313257</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.404185</td>\n",
       "      <td>0.430151</td>\n",
       "      <td>0.401677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.257400</td>\n",
       "      <td>1.297844</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.404436</td>\n",
       "      <td>0.449013</td>\n",
       "      <td>0.411582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>1.227500</td>\n",
       "      <td>1.278997</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.454632</td>\n",
       "      <td>0.450768</td>\n",
       "      <td>0.432374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.243300</td>\n",
       "      <td>1.222889</td>\n",
       "      <td>0.535000</td>\n",
       "      <td>0.550612</td>\n",
       "      <td>0.498043</td>\n",
       "      <td>0.500287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.210100</td>\n",
       "      <td>1.208779</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.442450</td>\n",
       "      <td>0.442952</td>\n",
       "      <td>0.413967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>1.103000</td>\n",
       "      <td>1.151379</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.458979</td>\n",
       "      <td>0.467659</td>\n",
       "      <td>0.434205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>266</td>\n",
       "      <td>1.070200</td>\n",
       "      <td>1.151151</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.528369</td>\n",
       "      <td>0.562321</td>\n",
       "      <td>0.524534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>304</td>\n",
       "      <td>1.035700</td>\n",
       "      <td>1.146813</td>\n",
       "      <td>0.555000</td>\n",
       "      <td>0.526339</td>\n",
       "      <td>0.501133</td>\n",
       "      <td>0.484879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>0.896900</td>\n",
       "      <td>1.121941</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.483560</td>\n",
       "      <td>0.483326</td>\n",
       "      <td>0.458052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.945700</td>\n",
       "      <td>1.074277</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.484548</td>\n",
       "      <td>0.507675</td>\n",
       "      <td>0.477760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>418</td>\n",
       "      <td>0.914500</td>\n",
       "      <td>1.028252</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.487238</td>\n",
       "      <td>0.476207</td>\n",
       "      <td>0.457808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>456</td>\n",
       "      <td>0.763100</td>\n",
       "      <td>0.990230</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.487199</td>\n",
       "      <td>0.505766</td>\n",
       "      <td>0.485051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>494</td>\n",
       "      <td>0.723300</td>\n",
       "      <td>0.984288</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.538692</td>\n",
       "      <td>0.548115</td>\n",
       "      <td>0.532668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:51:26,503] Trial 1 finished with value: 0.9814819097518921 and parameters: {'learning_rate': 2.3692291381434653e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 8, 'warmup_steps': 275, 'weight_decay': 0.06473814052081792, 'logging_steps': 38}. Best is trial 0 with value: 1.3454028367996216.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:37, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.984200</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.538692</td>\n",
       "      <td>0.548115</td>\n",
       "      <td>0.532668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.746600</td>\n",
       "      <td>0.985528</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.504138</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.494225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.626100</td>\n",
       "      <td>0.980186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501125</td>\n",
       "      <td>0.496630</td>\n",
       "      <td>0.488163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.616000</td>\n",
       "      <td>0.975552</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.528474</td>\n",
       "      <td>0.528348</td>\n",
       "      <td>0.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.663200</td>\n",
       "      <td>0.994522</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.553838</td>\n",
       "      <td>0.556448</td>\n",
       "      <td>0.544973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.647300</td>\n",
       "      <td>1.023028</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.523973</td>\n",
       "      <td>0.543295</td>\n",
       "      <td>0.518989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.567500</td>\n",
       "      <td>1.078090</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.466647</td>\n",
       "      <td>0.497703</td>\n",
       "      <td>0.465626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.602300</td>\n",
       "      <td>1.054693</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.495916</td>\n",
       "      <td>0.501183</td>\n",
       "      <td>0.488081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>1.089264</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.457970</td>\n",
       "      <td>0.468915</td>\n",
       "      <td>0.451698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.584100</td>\n",
       "      <td>1.040397</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.517690</td>\n",
       "      <td>0.523955</td>\n",
       "      <td>0.514408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.558800</td>\n",
       "      <td>1.091608</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.536103</td>\n",
       "      <td>0.543657</td>\n",
       "      <td>0.524218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.554100</td>\n",
       "      <td>1.130777</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.452328</td>\n",
       "      <td>0.468071</td>\n",
       "      <td>0.439874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>1.187072</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.500361</td>\n",
       "      <td>0.495744</td>\n",
       "      <td>0.478437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:52:05,739] Trial 2 finished with value: 1.1223053932189941 and parameters: {'learning_rate': 2.030293369798623e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 8, 'warmup_steps': 354, 'weight_decay': 0.014073899480919307, 'logging_steps': 15}. Best is trial 0 with value: 1.3454028367996216.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>1.074556</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.486690</td>\n",
       "      <td>0.480294</td>\n",
       "      <td>0.469425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.609800</td>\n",
       "      <td>1.069332</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.489188</td>\n",
       "      <td>0.492781</td>\n",
       "      <td>0.484686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.593400</td>\n",
       "      <td>1.128674</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.513571</td>\n",
       "      <td>0.545038</td>\n",
       "      <td>0.511761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:52:41,421] Trial 3 finished with value: 1.0940974950790405 and parameters: {'learning_rate': 1.580609382437937e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 264, 'weight_decay': 0.021918310609759444, 'logging_steps': 45}. Best is trial 0 with value: 1.3454028367996216.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.534600</td>\n",
       "      <td>1.076409</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.524824</td>\n",
       "      <td>0.530203</td>\n",
       "      <td>0.520283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:53:01,429] Trial 4 finished with value: 1.0789555311203003 and parameters: {'learning_rate': 1.724955213801001e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'warmup_steps': 396, 'weight_decay': 0.014939016994306522, 'logging_steps': 41}. Best is trial 0 with value: 1.3454028367996216.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>1.091168</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509809</td>\n",
       "      <td>0.514549</td>\n",
       "      <td>0.505796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.502500</td>\n",
       "      <td>1.088292</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.532322</td>\n",
       "      <td>0.536291</td>\n",
       "      <td>0.527933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>1.147666</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.487854</td>\n",
       "      <td>0.482372</td>\n",
       "      <td>0.477287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.513100</td>\n",
       "      <td>1.155363</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.487251</td>\n",
       "      <td>0.482974</td>\n",
       "      <td>0.481469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.499400</td>\n",
       "      <td>1.189727</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.456928</td>\n",
       "      <td>0.435332</td>\n",
       "      <td>0.435079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.459600</td>\n",
       "      <td>1.292366</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.500051</td>\n",
       "      <td>0.497065</td>\n",
       "      <td>0.479685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.517900</td>\n",
       "      <td>1.269210</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.417276</td>\n",
       "      <td>0.441402</td>\n",
       "      <td>0.420672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>1.337878</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.496217</td>\n",
       "      <td>0.492435</td>\n",
       "      <td>0.488327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.516600</td>\n",
       "      <td>1.359655</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.464432</td>\n",
       "      <td>0.447997</td>\n",
       "      <td>0.447142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>1.355888</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.480689</td>\n",
       "      <td>0.496588</td>\n",
       "      <td>0.480172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>1.397857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.501942</td>\n",
       "      <td>0.498461</td>\n",
       "      <td>0.494870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:53:55,891] Trial 5 finished with value: 1.3740437030792236 and parameters: {'learning_rate': 2.5132338807800035e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'warmup_steps': 97, 'weight_decay': 0.043008086426215286, 'logging_steps': 11}. Best is trial 5 with value: 1.3740437030792236.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>1.371545</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.479780</td>\n",
       "      <td>0.474438</td>\n",
       "      <td>0.473471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:54:15,965] Trial 6 finished with value: 1.3923614025115967 and parameters: {'learning_rate': 1.5999326802830352e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'warmup_steps': 382, 'weight_decay': 0.064610561082195, 'logging_steps': 40}. Best is trial 6 with value: 1.3923614025115967.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 01:02, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>1.474044</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.479199</td>\n",
       "      <td>0.450465</td>\n",
       "      <td>0.455970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.319000</td>\n",
       "      <td>1.539711</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.479047</td>\n",
       "      <td>0.460264</td>\n",
       "      <td>0.458375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.221500</td>\n",
       "      <td>1.686386</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.528105</td>\n",
       "      <td>0.522086</td>\n",
       "      <td>0.505779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.224300</td>\n",
       "      <td>1.829498</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.456864</td>\n",
       "      <td>0.486198</td>\n",
       "      <td>0.459476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>1.775300</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.511195</td>\n",
       "      <td>0.456479</td>\n",
       "      <td>0.461541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>1.921588</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.522061</td>\n",
       "      <td>0.531432</td>\n",
       "      <td>0.510897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>287</td>\n",
       "      <td>0.636700</td>\n",
       "      <td>1.666434</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.521192</td>\n",
       "      <td>0.495318</td>\n",
       "      <td>0.481143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.801695</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.498006</td>\n",
       "      <td>0.484227</td>\n",
       "      <td>0.460377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>369</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>1.557632</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.499963</td>\n",
       "      <td>0.464336</td>\n",
       "      <td>0.472261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:55:19,804] Trial 7 finished with value: 1.5249067544937134 and parameters: {'learning_rate': 4.580927725799464e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 8, 'warmup_steps': 273, 'weight_decay': 0.02610899653475637, 'logging_steps': 41}. Best is trial 7 with value: 1.5249067544937134.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.223000</td>\n",
       "      <td>1.496961</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.483486</td>\n",
       "      <td>0.491124</td>\n",
       "      <td>0.482984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.164700</td>\n",
       "      <td>1.551938</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.500025</td>\n",
       "      <td>0.483371</td>\n",
       "      <td>0.487331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.477007</td>\n",
       "      <td>0.461832</td>\n",
       "      <td>0.463541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>1.856061</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.489444</td>\n",
       "      <td>0.467329</td>\n",
       "      <td>0.472677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:56:09,206] Trial 8 finished with value: 1.9304604530334473 and parameters: {'learning_rate': 2.1296975620192148e-05, 'num_train_epochs': 5, 'per_device_train_batch_size': 32, 'warmup_steps': 406, 'weight_decay': 0.05954968580621739, 'logging_steps': 27}. Best is trial 8 with value: 1.9304604530334473.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:18, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>1.979225</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.485153</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>0.471009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7/7 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:56:29,291] Trial 9 finished with value: 2.0310754776000977 and parameters: {'learning_rate': 2.018002883120059e-05, 'num_train_epochs': 2, 'per_device_train_batch_size': 32, 'warmup_steps': 200, 'weight_decay': 0.060522285874736945, 'logging_steps': 34}. Best is trial 9 with value: 2.0310754776000977.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.214300</td>\n",
       "      <td>2.063491</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.477530</td>\n",
       "      <td>0.462540</td>\n",
       "      <td>0.461577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>2.194932</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>0.492920</td>\n",
       "      <td>0.493152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>2.216149</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.473860</td>\n",
       "      <td>0.468412</td>\n",
       "      <td>0.464063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>2.269162</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.472818</td>\n",
       "      <td>0.459964</td>\n",
       "      <td>0.460762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>2.368289</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.448401</td>\n",
       "      <td>0.434042</td>\n",
       "      <td>0.432374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:57:06,353] Trial 10 finished with value: 2.3621389865875244 and parameters: {'learning_rate': 1.0147384447897334e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 1, 'weight_decay': 0.09650753346648197, 'logging_steps': 28}. Best is trial 10 with value: 2.3621389865875244.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>2.435663</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.466442</td>\n",
       "      <td>0.457653</td>\n",
       "      <td>0.452611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>2.668660</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.494846</td>\n",
       "      <td>0.490601</td>\n",
       "      <td>0.486714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>2.623002</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>0.487457</td>\n",
       "      <td>0.486044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>2.855290</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.466426</td>\n",
       "      <td>0.452248</td>\n",
       "      <td>0.448753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>2.805862</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.475980</td>\n",
       "      <td>0.461553</td>\n",
       "      <td>0.460059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:57:43,362] Trial 11 finished with value: 2.8058624267578125 and parameters: {'learning_rate': 1.076188773546749e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 75, 'weight_decay': 0.09967738687723814, 'logging_steps': 30}. Best is trial 11 with value: 2.8058624267578125.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>2.938859</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.490443</td>\n",
       "      <td>0.500690</td>\n",
       "      <td>0.489290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>3.013297</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.496004</td>\n",
       "      <td>0.489058</td>\n",
       "      <td>0.485984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>3.159477</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.516049</td>\n",
       "      <td>0.503288</td>\n",
       "      <td>0.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>3.170346</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520025</td>\n",
       "      <td>0.495955</td>\n",
       "      <td>0.503854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>3.216661</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.480701</td>\n",
       "      <td>0.458523</td>\n",
       "      <td>0.462742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:58:20,472] Trial 12 finished with value: 3.2061846256256104 and parameters: {'learning_rate': 1.0180447798719254e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 23, 'weight_decay': 0.09865046620122744, 'logging_steps': 26}. Best is trial 12 with value: 3.2061846256256104.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:37, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>3.462053</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.475809</td>\n",
       "      <td>0.461524</td>\n",
       "      <td>0.459085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>3.496941</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.519742</td>\n",
       "      <td>0.523049</td>\n",
       "      <td>0.511122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>3.528466</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.506351</td>\n",
       "      <td>0.498318</td>\n",
       "      <td>0.494255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>3.555010</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.502269</td>\n",
       "      <td>0.492872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>3.493671</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.508450</td>\n",
       "      <td>0.502678</td>\n",
       "      <td>0.499739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>3.593860</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.525699</td>\n",
       "      <td>0.507508</td>\n",
       "      <td>0.509974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>3.588603</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.510999</td>\n",
       "      <td>0.493754</td>\n",
       "      <td>0.496581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:58:59,107] Trial 13 finished with value: 3.5894458293914795 and parameters: {'learning_rate': 1.0524170111694741e-05, 'num_train_epochs': 3, 'per_device_train_batch_size': 16, 'warmup_steps': 17, 'weight_decay': 0.09568843053298237, 'logging_steps': 21}. Best is trial 13 with value: 3.5894458293914795.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.595148</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.516030</td>\n",
       "      <td>0.498300</td>\n",
       "      <td>0.501729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>3.606142</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.512579</td>\n",
       "      <td>0.499956</td>\n",
       "      <td>0.498235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.632821</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.521577</td>\n",
       "      <td>0.509263</td>\n",
       "      <td>0.507704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.644372</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.526105</td>\n",
       "      <td>0.517843</td>\n",
       "      <td>0.513594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.650370</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.518984</td>\n",
       "      <td>0.512437</td>\n",
       "      <td>0.507165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>3.694022</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.519914</td>\n",
       "      <td>0.511195</td>\n",
       "      <td>0.509432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.753603</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.517302</td>\n",
       "      <td>0.507826</td>\n",
       "      <td>0.504807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>3.806148</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.494122</td>\n",
       "      <td>0.469137</td>\n",
       "      <td>0.477146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.097900</td>\n",
       "      <td>4.041192</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.500676</td>\n",
       "      <td>0.465555</td>\n",
       "      <td>0.470854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.193600</td>\n",
       "      <td>3.917047</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.476798</td>\n",
       "      <td>0.447990</td>\n",
       "      <td>0.450472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 08:59:50,652] Trial 14 finished with value: 3.9500012397766113 and parameters: {'learning_rate': 1.222590365927783e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 494, 'weight_decay': 0.0844321290113328, 'logging_steps': 19}. Best is trial 14 with value: 3.9500012397766113.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>3.961587</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.477669</td>\n",
       "      <td>0.450931</td>\n",
       "      <td>0.457516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.990739</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>0.447147</td>\n",
       "      <td>0.452609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.012156</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.476057</td>\n",
       "      <td>0.451944</td>\n",
       "      <td>0.457596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.045809</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.480982</td>\n",
       "      <td>0.459334</td>\n",
       "      <td>0.463928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.093620</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.472345</td>\n",
       "      <td>0.454342</td>\n",
       "      <td>0.456564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.163657</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.466005</td>\n",
       "      <td>0.446690</td>\n",
       "      <td>0.449891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.221067</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.468920</td>\n",
       "      <td>0.449928</td>\n",
       "      <td>0.452739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>4.287369</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.491330</td>\n",
       "      <td>0.469819</td>\n",
       "      <td>0.472962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.103500</td>\n",
       "      <td>4.088325</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.522776</td>\n",
       "      <td>0.501888</td>\n",
       "      <td>0.501898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>4.131988</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.498532</td>\n",
       "      <td>0.475498</td>\n",
       "      <td>0.476036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 09:00:42,223] Trial 15 finished with value: 4.131988048553467 and parameters: {'learning_rate': 1.3237510733122473e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 478, 'weight_decay': 0.04383983723270152, 'logging_steps': 20}. Best is trial 15 with value: 4.131988048553467.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:50, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>4.126797</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.493373</td>\n",
       "      <td>0.471151</td>\n",
       "      <td>0.472293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>4.082470</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.506565</td>\n",
       "      <td>0.485936</td>\n",
       "      <td>0.488290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.084157</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.506598</td>\n",
       "      <td>0.484178</td>\n",
       "      <td>0.488272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.159057</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.494462</td>\n",
       "      <td>0.471897</td>\n",
       "      <td>0.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.205865</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.485499</td>\n",
       "      <td>0.463534</td>\n",
       "      <td>0.469218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.389199</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.487441</td>\n",
       "      <td>0.464427</td>\n",
       "      <td>0.470485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.428027</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.502853</td>\n",
       "      <td>0.495065</td>\n",
       "      <td>0.490388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>4.286833</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.501478</td>\n",
       "      <td>0.485902</td>\n",
       "      <td>0.482324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.113700</td>\n",
       "      <td>4.726232</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.465261</td>\n",
       "      <td>0.444421</td>\n",
       "      <td>0.445668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>4.374190</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.506367</td>\n",
       "      <td>0.494358</td>\n",
       "      <td>0.488697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 09:01:33,642] Trial 16 finished with value: 4.374189853668213 and parameters: {'learning_rate': 1.3705638063275218e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 459, 'weight_decay': 0.04530061178135696, 'logging_steps': 20}. Best is trial 16 with value: 4.374189853668213.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:49, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>4.373491</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.500782</td>\n",
       "      <td>0.489248</td>\n",
       "      <td>0.484815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>4.401940</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.490165</td>\n",
       "      <td>0.476534</td>\n",
       "      <td>0.475301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>4.429142</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.494159</td>\n",
       "      <td>0.479772</td>\n",
       "      <td>0.480174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>4.403307</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.519688</td>\n",
       "      <td>0.502814</td>\n",
       "      <td>0.505103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>4.441144</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.503725</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.492997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>4.443211</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.493617</td>\n",
       "      <td>0.476776</td>\n",
       "      <td>0.479481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>4.808409</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.473955</td>\n",
       "      <td>0.471572</td>\n",
       "      <td>0.463790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>4.534966</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.503651</td>\n",
       "      <td>0.472060</td>\n",
       "      <td>0.482037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.577677</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.469074</td>\n",
       "      <td>0.469530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 09:02:24,355] Trial 17 finished with value: 4.733877658843994 and parameters: {'learning_rate': 1.3408027010562741e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 475, 'weight_decay': 0.042594903934789714, 'logging_steps': 21}. Best is trial 17 with value: 4.733877658843994.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:55, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.742109</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.470129</td>\n",
       "      <td>0.451532</td>\n",
       "      <td>0.453289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.731967</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.477337</td>\n",
       "      <td>0.456077</td>\n",
       "      <td>0.459362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.724521</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.479607</td>\n",
       "      <td>0.457037</td>\n",
       "      <td>0.461513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.737192</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.477902</td>\n",
       "      <td>0.453235</td>\n",
       "      <td>0.459464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.758622</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.486443</td>\n",
       "      <td>0.469932</td>\n",
       "      <td>0.472157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.626011</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.483462</td>\n",
       "      <td>0.464145</td>\n",
       "      <td>0.468705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.453633</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.494417</td>\n",
       "      <td>0.476327</td>\n",
       "      <td>0.480147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>4.464364</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.506701</td>\n",
       "      <td>0.489023</td>\n",
       "      <td>0.491713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.505257</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.499106</td>\n",
       "      <td>0.480675</td>\n",
       "      <td>0.484758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.542383</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.499106</td>\n",
       "      <td>0.480675</td>\n",
       "      <td>0.484758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>4.904364</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.492566</td>\n",
       "      <td>0.484070</td>\n",
       "      <td>0.478788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>4.883677</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.487872</td>\n",
       "      <td>0.477424</td>\n",
       "      <td>0.470785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>5.136693</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.472662</td>\n",
       "      <td>0.465171</td>\n",
       "      <td>0.457278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>5.129542</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.444248</td>\n",
       "      <td>0.438950</td>\n",
       "      <td>0.431166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>5.042293</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.473860</td>\n",
       "      <td>0.462610</td>\n",
       "      <td>0.460536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>4.707678</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.484316</td>\n",
       "      <td>0.460055</td>\n",
       "      <td>0.467194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>5.106423</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.478731</td>\n",
       "      <td>0.460188</td>\n",
       "      <td>0.461399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>5.203573</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.469777</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>0.451999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 09:03:21,705] Trial 18 finished with value: 5.156001567840576 and parameters: {'learning_rate': 1.4342731206032218e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 447, 'weight_decay': 0.020525426848912655, 'logging_steps': 11}. Best is trial 18 with value: 5.156001567840576.\n",
      "/tmp/ipykernel_12864/556361435.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "/tmp/ipykernel_12864/556361435.py:10: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform('weight_decay', 0.01, 0.1)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.154465</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.468033</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>0.452456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.146831</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.466919</td>\n",
       "      <td>0.458473</td>\n",
       "      <td>0.453457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.150245</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.454815</td>\n",
       "      <td>0.438288</td>\n",
       "      <td>0.439429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>5.160800</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.459813</td>\n",
       "      <td>0.443050</td>\n",
       "      <td>0.444042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.166315</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.456610</td>\n",
       "      <td>0.439050</td>\n",
       "      <td>0.440141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>5.179380</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.461608</td>\n",
       "      <td>0.446984</td>\n",
       "      <td>0.445591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>5.060487</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.495486</td>\n",
       "      <td>0.492716</td>\n",
       "      <td>0.482350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>5.150709</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.497713</td>\n",
       "      <td>0.485420</td>\n",
       "      <td>0.479594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>5.212040</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.487901</td>\n",
       "      <td>0.476444</td>\n",
       "      <td>0.470945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>4.854087</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.524569</td>\n",
       "      <td>0.519429</td>\n",
       "      <td>0.509692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>4.922896</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.500140</td>\n",
       "      <td>0.492233</td>\n",
       "      <td>0.489345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.150900</td>\n",
       "      <td>5.228169</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.519399</td>\n",
       "      <td>0.495326</td>\n",
       "      <td>0.489617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.102300</td>\n",
       "      <td>5.066281</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.486530</td>\n",
       "      <td>0.465417</td>\n",
       "      <td>0.468505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.113800</td>\n",
       "      <td>4.708604</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.406926</td>\n",
       "      <td>0.424938</td>\n",
       "      <td>0.408469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>4.788087</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.519990</td>\n",
       "      <td>0.474183</td>\n",
       "      <td>0.476635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>4.876805</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.519592</td>\n",
       "      <td>0.509535</td>\n",
       "      <td>0.489707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.281200</td>\n",
       "      <td>4.514975</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.531125</td>\n",
       "      <td>0.520351</td>\n",
       "      <td>0.510607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.605800</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.512755</td>\n",
       "      <td>0.515170</td>\n",
       "      <td>0.509269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>4.084967</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.548900</td>\n",
       "      <td>0.522765</td>\n",
       "      <td>0.524865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.246700</td>\n",
       "      <td>4.231753</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.522165</td>\n",
       "      <td>0.494072</td>\n",
       "      <td>0.498405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-28 09:04:20,562] Trial 19 finished with value: 4.231752872467041 and parameters: {'learning_rate': 2.8611763187481424e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 325, 'weight_decay': 0.010464033538003837, 'logging_steps': 10}. Best is trial 18 with value: 5.156001567840576.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "194a6a88-1fa1-43af-8c9d-f0baa90d8fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.4342731206032218e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 447, 'weight_decay': 0.020525426848912655, 'logging_steps': 11}\n"
     ]
    }
   ],
   "source": [
    "best_hyperparameters = study.best_params\n",
    "print(best_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = {'learning_rate': 1.4342731206032218e-05, 'num_train_epochs': 4, 'per_device_train_batch_size': 16, 'warmup_steps': 447, 'weight_decay': 0.020525426848912655, 'logging_steps': 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96525d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fbc17ba-7da9-492b-8ccd-7911c7c131b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Training on best hyper parametr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a86bebbd-08fa-4967-a568-4d1b52d8139f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "temp_output_dir = tempfile.mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2e19295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=temp_output_dir,\n",
    "    learning_rate=best_hyperparameters['learning_rate'],\n",
    "    per_device_train_batch_size=best_hyperparameters['per_device_train_batch_size'],\n",
    "    weight_decay=best_hyperparameters['weight_decay'],\n",
    "    warmup_steps=best_hyperparameters['warmup_steps'],\n",
    "    num_train_epochs=best_hyperparameters['num_train_epochs'],\n",
    "    evaluation_strategy=\"epoch\", \n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\", \n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, \n",
    "    compute_metrics=compute_metrics \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a8b92c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>4.246321</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.503709</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.483209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.417559</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.481966</td>\n",
       "      <td>0.468718</td>\n",
       "      <td>0.471000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>4.477961</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507062</td>\n",
       "      <td>0.501203</td>\n",
       "      <td>0.500455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>4.557808</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.496963</td>\n",
       "      <td>0.490987</td>\n",
       "      <td>0.489769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.009584885090589523, metrics={'train_runtime': 55.0216, 'train_samples_per_second': 58.159, 'train_steps_per_second': 3.635, 'total_flos': 345358065024000.0, 'train_loss': 0.009584885090589523, 'epoch': 4.0})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1e4a7d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.5578083992004395,\n",
       " 'eval_accuracy': 0.49,\n",
       " 'eval_precision': 0.4969630548662806,\n",
       " 'eval_recall': 0.4909874312483008,\n",
       " 'eval_f1': 0.4897689913773623,\n",
       " 'eval_runtime': 0.7801,\n",
       " 'eval_samples_per_second': 256.379,\n",
       " 'eval_steps_per_second': 32.047,\n",
       " 'epoch': 4.0}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n",
    "eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4941a6e4-0d24-4fa0-a1ee-d761aaea0ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ipl_match_win_prediction_model/tokenizer_config.json',\n",
       " 'ipl_match_win_prediction_model/special_tokens_map.json',\n",
       " 'ipl_match_win_prediction_model/vocab.txt',\n",
       " 'ipl_match_win_prediction_model/added_tokens.json')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model_name = \"ipl_match_win_prediction_model\"\n",
    "trainer.save_model(gen_model_name)\n",
    "tokenizer.save_pretrained(gen_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a7b3342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5344b96-0e66-4ddc-8614-cb5d115e53bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = BertForSequenceClassification.from_pretrained(gen_model_name)\n",
    "final_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "75add3cf-e5b1-4ae9-8745-631640b00712",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00569811, 0.01069026, 0.5355258 , 0.00911079, 0.26537305,\n",
       "        0.1115776 , 0.03976409, 0.00922389, 0.00236768, 0.0106687 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"who is going to win if match is played beteen KKR and DC\"\n",
    "inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to(device)\n",
    "outputs = final_model(**inputs)\n",
    "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "predictions = predictions.cpu().detach().numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9548f600-e477-415c-836a-d98f8e0ecaec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_index = np.argmax(predictions)\n",
    "predicted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddc34512-d0c1-4e74-9e4d-1ec5e857d039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Sunrisers Hyderabad (SRH)',\n",
       " 1: 'Chennai Super Kings (CSK)',\n",
       " 2: 'Delhi Capitals (DC)',\n",
       " 3: 'Mumbai Indians (MI)',\n",
       " 4: 'Kings XI Punjab (KXIP)',\n",
       " 5: 'Royal Challengers Bangalore (RCB)',\n",
       " 6: 'Gujarat Titans (GT)',\n",
       " 7: 'Kolkata Knight Riders (KKR)',\n",
       " 8: 'Rajasthan Royals (RR)',\n",
       " 9: 'Lucknow Super Giants (LSG)'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_label = {idx: team for team, idx in label_mapping.items()}\n",
    "index_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8cc4fd65-0e9a-4323-bf9d-427f448711c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Delhi Capitals (DC)'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label = index_to_label[predicted_index]\n",
    "predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0c143-b4bb-4550-8f7c-3d470c28c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "model_name = \"pdp19/ipl_match_winner_predictor\"\n",
    "def get_winner(input_query):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "    inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to(device)\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    predictions = predictions.cpu().detach().numpy()\n",
    "\n",
    "    predicted_index = np.argmax(predictions)\n",
    "\n",
    "    index_to_label = {idx: team for team, idx in label_mapping.items()}\n",
    "\n",
    "    predicted_label = index_to_label[predicted_index]\n",
    "\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24b1a3-d4f8-4b17-80d6-5839b6f68431",
   "metadata": {},
   "source": [
    "### Download File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ca0489a-6712-4f71-b29e-4f750afaef04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='ipl_match_win_prediction_model.zip' target='_blank'>ipl_match_win_prediction_model.zip</a><br>"
      ],
      "text/plain": [
       "/home/ec2-user/SageMaker/ipl_match_win_prediction_model.zip"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "folder_path = 'ipl_match_win_prediction_model'\n",
    "shutil.make_archive(folder_path, 'zip', folder_path)\n",
    "display(FileLink(f'{folder_path}.zip'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5b95c0df-f991-4542-8018-10f559b18415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: missing URL\n",
      "Usage: wget [OPTION]... [URL]...\n",
      "\n",
      "Try `wget --help' for more options.\n"
     ]
    }
   ],
   "source": [
    "!wget -O WinPredictionBinaryClassification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c868fa38-e609-434c-a1fa-5fe0cec073ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='WinPredictionBinaryClassification.ipynb' target='_blank'>WinPredictionBinaryClassification.ipynb</a><br>"
      ],
      "text/plain": [
       "/home/ec2-user/SageMaker/WinPredictionBinaryClassification.ipynb"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "FileLink('WinPredictionBinaryClassification.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390a61b-2944-4f33-b848-a3120399674f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
